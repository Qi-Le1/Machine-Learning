{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn import datasets\n",
    "X, t = sk.datasets.load_boston(return_X_y=True)\n",
    "Y, u = sk.datasets.load_digits(n_class=10, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn import datasets\n",
    "X, t = sk.datasets.load_boston(return_X_y=True)\n",
    "Y, u = sk.datasets.load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn import datasets\n",
    "X, t = sk.datasets.load_boston(return_X_y=True)\n",
    "Y, u = sk.datasets.load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "\n",
    "def trainTestSplit_Boston(X, t, cut, test_size):\n",
    "    X_num = len(X)\n",
    "    train_index = []\n",
    "    for i in range(X_num):\n",
    "        train_index.append(i)\n",
    "\n",
    "    test_index = []\n",
    "    test_num = int(X_num * test_size)\n",
    "    size = X_num - test_num\n",
    "\n",
    "    X_train = np.zeros((size, 13))\n",
    "    t_train = np.zeros(size)\n",
    "\n",
    "    X_test = np.zeros((test_num, 13))\n",
    "    t_test = np.zeros(test_num)\n",
    "\n",
    "    for i in range(test_num):\n",
    "        randomIndex = int(np.random.uniform(0, len(train_index)))\n",
    "        test_index.append(train_index[randomIndex])\n",
    "        del train_index[randomIndex]\n",
    "\n",
    "    j = 0\n",
    "    for i in train_index:\n",
    "        X_train[j] = X[i]\n",
    "        if (t[i] >= cut):\n",
    "            t_train[j] = 1\n",
    "        else:\n",
    "            t_train[j] = 0\n",
    "        j += 1\n",
    "\n",
    "    j = 0\n",
    "    for i in test_index:\n",
    "        X_test[j] = X[i]\n",
    "        if (t[i] >= cut):\n",
    "            t_test[j] = 1\n",
    "        else:\n",
    "            t_test[j] = 0\n",
    "        j += 1\n",
    "\n",
    "    return X_train, t_train, X_test, t_test\n",
    "\n",
    "\n",
    "def trainTestSplit_digit(X, t, test_size):\n",
    "    shape = (64, 1)\n",
    "\n",
    "    X_num = len(X)\n",
    "    train_index = []\n",
    "    for i in range(X_num):\n",
    "        train_index.append(i)\n",
    "\n",
    "    test_index = []\n",
    "    test_num = int(X_num * test_size)\n",
    "    size = X_num - test_num\n",
    "\n",
    "    X_train = np.zeros((size, 64))\n",
    "    t_train = np.zeros(size)\n",
    "\n",
    "    X_test = np.zeros((test_num, 64))\n",
    "    t_test = np.zeros(test_num)\n",
    "\n",
    "    for i in range(test_num):\n",
    "        randomIndex = int(np.random.uniform(0, len(train_index)))\n",
    "        test_index.append(train_index[randomIndex])\n",
    "        del train_index[randomIndex]\n",
    "\n",
    "    j = 0\n",
    "    for i in train_index:\n",
    "        X_train[j] = X[i]\n",
    "        t_train[j] = t[i]\n",
    "        j += 1\n",
    "\n",
    "    j = 0\n",
    "    for i in test_index:\n",
    "        X_test[j] = X[i]\n",
    "        t_test[j] = t[i]\n",
    "        j += 1\n",
    "\n",
    "    return X_train, t_train, X_test, t_test\n",
    "\n",
    "def trainset_percentage(X, t, sep_ratio):\n",
    "    # Separate data into training set and testing set.\n",
    "    X_train_size = int(len(X) * (sep_ratio / 100))\n",
    "\n",
    "    return X[:X_train_size], t[:X_train_size], X_train_size\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(Y_pred, Y_label):\n",
    "    # prediction accuracy\n",
    "    acc = 1 - np.mean(np.abs(Y_pred - Y_label))\n",
    "    return acc\n",
    "\n",
    "def train_model(X_train_data, Y_train_data,target_label):\n",
    "\n",
    "    X = X_train_data\n",
    "    Y = Y_train_data\n",
    "    feature_num = len(X[0])\n",
    "\n",
    "    pai = []\n",
    "    for i in range(target_label):\n",
    "        pai.append(len(X[Y == i]) / len(X))\n",
    "\n",
    "    miu = []\n",
    "    standard_deviation = []\n",
    "\n",
    "    for i in range(target_label):\n",
    "        miu_small = []\n",
    "        for j in range(feature_num):\n",
    "            miu_small.append(np.mean(X[Y == i][:, j],axis=0))\n",
    "        miu.append(miu_small)\n",
    "\n",
    "    for i in range(target_label):\n",
    "        standard_deviation_small = []\n",
    "        for j in range(feature_num):\n",
    "            standard_deviation_small.append(np.std(X[Y == i][:, j], axis=0))\n",
    "        standard_deviation.append(standard_deviation_small)\n",
    "\n",
    "    return pai,miu,standard_deviation\n",
    "\n",
    "def predict_model(pai,miu,standard_deviation,X_data,Y_data,target_label):\n",
    "    data_length = len(X_data)\n",
    "    prediction = [[] for j in range(len(X))]\n",
    "    feature_num = len(X_data[0])\n",
    "    #data = np.array(data)\n",
    "    #self.std\n",
    "    for i in range(data_length):\n",
    "        akc = [[] for q in range(target_label)]\n",
    "        for j in range(target_label):\n",
    "            x_pi = np.log(pai[j])\n",
    "            x_sigma = []\n",
    "            x_mu = []\n",
    "\n",
    "            for k in range(feature_num):\n",
    "                if standard_deviation[j][k] != 0:\n",
    "                    x_sigma.append(np.log(standard_deviation[j][k]))\n",
    "                    parameter = np.dot(standard_deviation[j][k],standard_deviation[j][k])\n",
    "                    x_mu.append( 0.5 * np.dot((X_data[i, k] - miu[j][k]),(X_data[i, k] - miu[j][k])) *  parameter)\n",
    "                else:\n",
    "                    x_sigma.append(0)\n",
    "                    x_mu.append(0)\n",
    "\n",
    "            a = sum(x_sigma)\n",
    "            b = sum(x_mu)\n",
    "            akc[j] = x_pi - sum(x_sigma) - sum(x_mu)\n",
    "            akc\n",
    "        prediction[i] = akc.index(max(akc))\n",
    "    return prediction\n",
    "\n",
    "median = np.median(t)  # Fine the median number\n",
    "seventy_five_percentile = np.percentile(t, 75)  # Find the 75th percentile number\n",
    "iteration = 100\n",
    "learning_rate = 0.2\n",
    "\n",
    "evaluation_number = 1\n",
    "vector = [50]\n",
    "train_loss = [0, 0, 0, 0, 0, 0]\n",
    "test_loss = [0, 0, 0, 0, 0, 0]\n",
    "train_acc = [0,0,0,0,0]\n",
    "digit_train_loss = [0,0,0,0,0]\n",
    "for i in range(1, evaluation_number + 1):\n",
    "    # Randomize the 80-20 split\n",
    "    X_train_50, t_train_50, X_test_50, t_test_50 = trainTestSplit_Boston(X, t, median, 0.2)\n",
    "    X_train_75, t_train_75, X_test_75, t_test_75 = trainTestSplit_Boston(X, t, seventy_five_percentile, 0.2)\n",
    "    Y_train_digit, u_train_digit, Y_test_digit, u_test_digit = trainTestSplit_digit(Y, u, 0.2)\n",
    "\n",
    "    vector_order = 0\n",
    "    # print(X_train_50.shape)\n",
    "    for j in vector:\n",
    "        X_train_50_j, t_train_50_j, Boston_train_size_50 = trainset_percentage(X_train_50, t_train_50, j)\n",
    "        X_train_75_j, t_train_75_j, Boston_train_size_75 = trainset_percentage(X_train_75, t_train_75, j)\n",
    "        Y_train_digit_j, u_train_digit_j, digit_train_size = trainset_percentage(Y_train_digit, u_train_digit, j)\n",
    "\n",
    "        pai_boston_50,miu_boston_50,standard_deviation_boston_50 = train_model(X_train_50_j, t_train_50_j,2)\n",
    "        pai_boston_75,miu_boston_75,standard_deviation_boston_75 = train_model(X_train_75_j, t_train_75_j,2)\n",
    "        pai__digit,miu_digit,standard_deviation_digit = train_model(Y_train_digit_j, u_train_digit_j,10)\n",
    "\n",
    "        pred_Boston_50 = predict_model(pai_boston_50,miu_boston_50,standard_deviation_boston_50,X_train_50_j,t_train_50_j,2)\n",
    "        pred_Boston_75 = predict_model(pai_boston_75,miu_boston_75,standard_deviation_boston_75, X_train_75_j, t_train_75_j, 2)\n",
    "        pred_digit = predict_model(pai__digit,miu_digit,standard_deviation_digit , Y_train_digit_j, u_train_digit_j, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #for o in range(iteration):\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()#train_loss[vector_order] += ( cross_entropy_loss(y_train_pred, t_train_50_j) / len(X_train_50_j))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
